# Results for CB8
#
# This file will be automatically parsed.  It must contain the following seven elements:
# predictions, participant name, participant organization, name of method, software listing, method, method category, and ranked.
# These elements must be provided in the order shown.
# The file name must begin with the word "CB8" and then be followed by an underscore or dash.
#
# FILE FORMAT: All comment lines in this file (which begin with #) will be ignored.
# Please use only UTF-8 characters in the non-comment fields. If your information (e.g. your name, etc.)
# contains a non-UTF-8 character, you may note it in comments near that entry.
#
#
# PREDICTIONS
# Please explicitly describe how you handle ions and pKa effects.
#
# The data in each prediction line should be structured as follows, with all (up to six) numbers in kcal/mol.
# host-guest ID (note that the host varies!), Free energy, free energy SEM, free energy model uncertainty,
# enthalpy, enthalpy SEM, enthalpy model uncertainty
# The free energy, free energy SEM, and free energy model uncertainty are REQUIRED.
# The corresponding quantities for binding enthalpy are optional.
#
# Note that the "model uncertainty" should be your estimate of ACCURACY of this particular approach
# for the compound considered.
#
# For the CB8 challenge, G8 and G9 are not part of this challenge hence they will not be judged, as
# literature values are available.
#
# The list of predictions must begin with the "Prediction:" keyword, as illustrated here.
Predictions:
CB8-G1, -7.87, 0.1, 1.07,,,
CB8-G2, -9.46, 0.1, 1.07,,,
CB8-G3, -9.01, 0.1, 1.07,,,
CB8-G4, -8.66, 0.1, 1.07,,,
CB8-G5, -8.94, 0.1, 1.07,,,
CB8-G6, -9.66, 0.1, 1.07,,,
CB8-G7, -10.56, 0.1, 1.07,,,

#
#
# Please list your name, using only UTF-8 characters as described above. The "Participant name:" entry is required.
Participant name:
Dylan SERILLON
#
#
# Please list your organization/affiliation, using only UTF-8 characters as described above.
Participant organization:
University of Barcelona
#
# Please provide a brief (40 character limit) informal yet informative name of the method used.
# If using an MD-based method we suggest using the format: Method/EnergyModel/WaterModel/Sampling/[Additional-details-here] , though your name must respect the 40 character limit.
# otherwise you may create your own following the sample text; please edit to your taste.
# The "Name:" keyword is required, as shown here.
# 40 character limit.
Name:
MACHINE-LEARNING/NNET/CORINA-descriptors
#
# All major software packages used and their versions
# Following is sample text; please edit to your taste.
# The "Software:" keyword is required.
Software:
xtb Version 6.1 
Gromacs Versions 2018.1
Open Babel 2.3.2
AutoDock Vina 1.1.2
MOE Version 2018
chimera production version 1.13.1
VMD for LINUXAMD64, version 1.9.3
#
# Methodology and computational details.
# Level of detail should be at least that used in a publication.
# Please include the values of key parameters, with units, and explain how any
# statistical uncertainties were estimated.
# Use as many lines of text as you need.
# Please explicitly describe how you handle ions (e.g. counterions) and pKa effects
# Following is sample text; please edit to your taste.
# All text following the "Method:" keyword will be regarded as part of your free text methods description.
Method:

SUBMISSION #4 OUT OF #4 -- UNRANKED SUBMISSION --


Free binding energy prediction using machine learning methods:

1) All the binding data from the Binding Database have been extracted and parsed. All the guest involved in the BindingDB and SAMPL3 challenge are reconstructed in two steps from SMILES using obabel: 
(i) generating 150 3D conformers based on Genetic-Algorithm 
(ii) and the selecting the lowest energy conformers. 
This conformers are then minimized at semi empirical level using xtb-GFN2B giving us an optimized 3D structure. The guest from SAMPL6 are extracted from repository and only minimized at semi empirical level using xtb-GFN2B giving us an optimized 3D structure. 
569 structures are extracted from this method. 

The same methods is used to reconstruct the hosts. In total, 23 different HOSTs are extracted and constructed from SMILES provided by the binding-DB following the same protocol.    
- For the hosts: BDBM197280, BDBM197287, BDBM197309, BDBM197310, BDBM36281 from the previous SAMPL challenges, SMILES reconstruction failed and we had to extract the 3D structure from different SAMPL-repository followed by minimization at semi empirical level using xtb-GFN2B giving us an optimized 3D structure. 
- BDBM36250 as well was impossible to reconstruct from SMILES, the cyclodextrine was so extracted from 4J3U pdb code that were structurally close, and manually modified with molecular builder, then minimized at semi empirical level with same procedure as before.
2) Both host and Guest structures are passed into the CORINA web-platform to compute 200 2D and 3D molecular descriptors for each Hosts and Guests.
3) The descriptors of the Guest-dataset and the Host-dataset are reduced separatly using the R software with different approaches: a) deleting the descriptors that have a near zero variance using Caret package ; b) deleting the most correlated descriptors using Caret package ; c) using principal component analysis (PCA) to combine descriptors that explain the most the variability.
4) Host-dataset and Guest-dataset are merged to form the final dataset where each lines correspond to a guest interacting with a specific host.

In order to predict the binding free energy, several machine learning models using regression are used: Neural network, knn, polynomial SVM and random forest. By modifying the parameters and using a repeated 10-fold cross validation on those ML models, thousands of different models are generated (respectively 186.500 nnet, 245.700 rf, 54.600 rf and 20 knn).
Both 30/70 and 20/80 data partition are tested and our prediction have been done in a 30/70 pratition, resulting in a set of 399 cases for training and 168 cases for the test set.

Our bestmodel, used to make predictions on SAMPL8, is a neural network using "nnet" function, which provided a TrainRMSE=1.07, TrainRsquare=0.77, TrainMAE=0.74 performances for trainingset and RMSE=0.65, Rsquare=1.05 and MAE=0.74 for the Testset, suggesting that the prediction is not excessively biased by overtraining.
#
#
# METHOD CATEGORY SECTION
#
# State which method category your prediction method is better described as:
# `Alchemical`, `Quantum`, `Other Physical` `Empirical`, `Mixed`, or `Other`.
# Pick only one category label.
# The `Category:` keyword is required.
Category:
Data-based Method - Machine learning Globalistic Model -
#
# All submissions must either be ranked or non-ranked.
# Only one ranked submission per participant is allowed.
# Multiple ranked submissions from the same participant will not be judged.
# Non-ranked submissions are accepted so we can verify that they were made before the deadline.
# The "Ranked:" keyword is required, and expects a Boolean value (True/False)
Ranked:
False